{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3068cd5-a29d-46d5-981a-6fbd80f6987c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Creating a Delta Table in Gold Zone with the Following Details:\n",
    "\n",
    "### 1. Fetching Statistics by Month and Year:\n",
    "   - Fetching the highest number of rides per driver by month.\n",
    "   - Identifying the highest number of trips and the highest-spent customer by both month and year.\n",
    "\n",
    "### 2. Identifying the Top-Rated Driver:\n",
    "   - Fetching the top-rated driver for the entire year.\n",
    "\n",
    "### 3. Analyzing Customer Behavior:\n",
    "   - Determining the highest-spent customer.\n",
    "   - Identifying the customer with the highest distance traveled.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e74f9be-8a4a-4025-8db1-64d5c7bb025b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import broadcast\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9699f2b2-e5fe-4bf8-b0ff-b4f1b2206378",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[7]: 3"
     ]
    }
   ],
   "source": [
    "# Read data from Delta Lake tables into DataFrames\n",
    "df1 = spark.read.load(\"/mnt/Deltalake/silver_Zone/Trip_Transactions_Fact\")\n",
    "df2 = spark.read.load(\"/mnt/Deltalake/silver_Zone/Customer_Dimension\")\n",
    "df3 = spark.read.load(\"/mnt/Deltalake/silver_Zone/driver_Dimension\")\n",
    "df4 = spark.read.load(\"/mnt/Deltalake/silver_Zone/Date_Dimension\")\n",
    "\n",
    "# Perform a broadcast join between df1 and df2 on the \"customer_id\" and \"Customer_id\" columns, respectively\n",
    "df5 = df1.join(broadcast(df2), df1.customer_id == df2.Customer_id)\n",
    "\n",
    "# Get the number of partitions in the resulting DataFrame df5\n",
    "df5.rdd.getNumPartitions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e18d36d1-ad66-4341-8933-1789f6ecae41",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Select specific columns from the DataFrame df5 and create a new DataFrame df5\n",
    "df5 = df5.select(\"trip_id\", \"Customer_Name\", \"customer_age\", \"customer_gender\", \"Trip_Date\", \"driver_id\", \"total_distance\", \"total_fare\", \"driver_id\")\n",
    "\n",
    "# Perform a broadcast join between df5 and df3 on the \"driver_id\" and \"driver_id\" columns, respectively\n",
    "df6 = df5.join(broadcast(df3), df3.driver_id == df5.driver_id)\n",
    "\n",
    "# Select specific columns from the DataFrame df6 and create a new DataFrame df6\n",
    "df6 = df6.select(\"trip_id\", \"Customer_Name\", \"customer_age\", \"customer_gender\", \"Trip_Date\", \"total_distance\", \"total_fare\", \"driver_name\", \"driver_age\", \"driver_gender\")\n",
    "\n",
    "# Perform a join between df6 and df4 on the \"Trip_Date\" and \"date\" columns, respectively\n",
    "df7 = df6.join(df4, df4.date == df6.Trip_Date)\n",
    "\n",
    "# Create or replace a temporary view named \"df7\" for further analysis or querying\n",
    "df7.createOrReplaceTempView(\"df7\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24b6e71a-7228-4160-a641-66c7fbf17f0e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Highest Spent & Highest distance travelled by Customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43483f39-e861-4bac-bcb8-cfa2cf20d5f5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Perform a SQL query on the DataFrame df7 to calculate customer spending and distance-related metrics\n",
    "df_customer_spent_distance = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        customer_name,\n",
    "        rank_total_distance,\n",
    "        rank_total_fare,\n",
    "        total_distance,\n",
    "        total_fare,\n",
    "        rank_trips_count,\n",
    "        CONCAT(month, year) AS month_year,\n",
    "        trips_count\n",
    "    FROM (\n",
    "        SELECT\n",
    "            customer_name,\n",
    "            RANK() OVER (PARTITION BY month, year ORDER BY total_distance DESC) AS rank_total_distance,\n",
    "            RANK() OVER (PARTITION BY month, year ORDER BY total_fare DESC) AS rank_total_fare,\n",
    "            total_distance,\n",
    "            total_fare,\n",
    "            month,\n",
    "            year,\n",
    "            RANK() OVER (PARTITION BY month, year ORDER BY trips_count DESC) AS rank_trips_count,\n",
    "            trips_count\n",
    "        FROM (\n",
    "            SELECT\n",
    "                customer_name,\n",
    "                SUM(total_fare) AS total_fare,\n",
    "                month,\n",
    "                year,\n",
    "                SUM(total_distance) AS total_distance,\n",
    "                COUNT(trip_id) AS trips_count\n",
    "            FROM df7\n",
    "            GROUP BY customer_name, month, year\n",
    "        )\n",
    "    )\n",
    "    WHERE rank_total_distance = 1 OR rank_total_fare = 1 OR rank_trips_count = 1\n",
    "    ORDER BY CONCAT(month, year)\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d49a016-a4a9-4a3c-935d-9ee04373e092",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Highest Rating & Highest Trips travelled by Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a455306-467d-4342-a801-822e4a4d0fd1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Perform a SQL query on the DataFrame df7 to calculate driver-related trip metrics\n",
    "df_driver_trips = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        driver_name,\n",
    "        CONCAT(month, year) AS year_Month,\n",
    "        count_trips\n",
    "    FROM (\n",
    "        SELECT\n",
    "            driver_name,\n",
    "            RANK() OVER (PARTITION BY month, year ORDER BY count_trips DESC) AS rank_count_trips,\n",
    "            month,\n",
    "            year,\n",
    "            count_trips\n",
    "        FROM (\n",
    "            SELECT\n",
    "                driver_name,\n",
    "                month,\n",
    "                year,\n",
    "                COUNT(trip_id) AS count_trips\n",
    "            FROM df7\n",
    "            GROUP BY driver_name, month, year\n",
    "        )\n",
    "    )\n",
    "    WHERE rank_count_trips = 1\n",
    "    ORDER BY CONCAT(month, year)\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "538ffccc-bb96-4329-b1c4-349dae5b3ff0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read data from a Delta Lake table into a DataFrame df8\n",
    "df8 = spark.read.load(\"/mnt/Deltalake/Bronze/Rewards_Points\")\n",
    "\n",
    "# Perform an inner join between df8 and df7 on the \"trip_id\" column and create a new DataFrame df9\n",
    "df9 = df8.join(df7, df7.trip_id == df8.trip_id)\n",
    "\n",
    "# Group by \"Customer_Name,\" \"Month,\" and \"year\" columns, summing up the \"customer_rating\" for each group, and create a new DataFrame df10\n",
    "df10 = df9.groupBy(\"Customer_Name\", \"Month\", \"year\").sum(\"customer_rating\")\n",
    "\n",
    "# Rename the summed column to \"Customer_Rating\" in the DataFrame df11\n",
    "df11 = df10.withColumnRenamed(\"sum(customer_rating)\", \"Customer_Rating\")\n",
    "\n",
    "# Group by \"driver_name,\" \"Month,\" and \"year\" columns, summing up the \"driver_rating\" for each group, and create a new DataFrame df12\n",
    "df12 = df9.groupBy(\"driver_name\", \"Month\", \"year\").sum(\"driver_rating\")\n",
    "\n",
    "# Rename the summed column to \"driver_Rating\" in the DataFrame df13\n",
    "df13 = df12.withColumnRenamed(\"sum(driver_rating)\", \"driver_Rating\")\n",
    "\n",
    "# Add a new column \"rank_driver_rating\" using the rank function over the partition of \"Month\" and \"Year\" based on \"driver_rating,\" and create a new DataFrame df14\n",
    "df14 = df13.withColumn(\"rank_driver_rating\", F.expr(\"rank() over(partition by concat(month, Year) order by driver_rating desc)\"))\n",
    "\n",
    "# Filter df14 to include only the rows where \"rank_driver_rating\" is equal to 1, and create a new DataFrame df15\n",
    "df15 = df14.filter(df14.rank_driver_rating == 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c16fdc3b-df22-4254-83c5-4ff5d4c43865",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>driver_name</th><th>Month</th><th>year</th><th>driver_Rating</th><th>rank_driver_rating</th></tr></thead><tbody><tr><td>Kapil</td><td>01</td><td>2023</td><td>124</td><td>1</td></tr><tr><td>Aaditya</td><td>02</td><td>2023</td><td>87</td><td>1</td></tr><tr><td>Kumar</td><td>03</td><td>2023</td><td>121</td><td>1</td></tr><tr><td>Nikshit</td><td>04</td><td>2023</td><td>115</td><td>1</td></tr><tr><td>Sam</td><td>05</td><td>2023</td><td>122</td><td>1</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Kapil",
         "01",
         "2023",
         124,
         1
        ],
        [
         "Aaditya",
         "02",
         "2023",
         87,
         1
        ],
        [
         "Kumar",
         "03",
         "2023",
         121,
         1
        ],
        [
         "Nikshit",
         "04",
         "2023",
         115,
         1
        ],
        [
         "Sam",
         "05",
         "2023",
         122,
         1
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "driver_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Month",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "year",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "driver_Rating",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "rank_driver_rating",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df15.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8dd2e430-214d-4755-9fa0-c367aa4423bf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Group by \"customer_name,\" \"month,\" and \"year\" columns, summing up the \"customer_rating\" for each group, and create a new DataFrame df12\n",
    "df12 = df11.groupBy(\"customer_name\", \"month\", \"year\").sum(\"customer_rating\")\n",
    "\n",
    "# Rename the summed column to \"customer_rating\" in the DataFrame df12\n",
    "df12 = df12.withColumnRenamed(\"sum(customer_rating)\", \"customer_rating\")\n",
    "\n",
    "# Add a new column \"rank_customer_rating\" using the rank function over the partition of \"month\" and \"year\" based on \"customer_rating,\" and create a new DataFrame df13\n",
    "df13 = df12.withColumn(\"rank_customer_rating\", F.expr(\"rank() over(partition by concat(month, Year) order by customer_rating desc)\"))\n",
    "\n",
    "# Filter df13 to include only the rows where \"rank_customer_rating\" is equal to 1, and create a new DataFrame df15\n",
    "df15 = df13.filter(df13.rank_customer_rating == 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33b408dc-4e1b-451f-b5ca-eb073c73ba2d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>customer_name</th><th>month</th><th>year</th><th>customer_rating</th><th>rank_customer_rating</th></tr></thead><tbody><tr><td>ABC2</td><td>01</td><td>2023</td><td>124</td><td>1</td></tr><tr><td>ABC6</td><td>02</td><td>2023</td><td>89</td><td>1</td></tr><tr><td>ABC32</td><td>03</td><td>2023</td><td>120</td><td>1</td></tr><tr><td>ABC3</td><td>04</td><td>2023</td><td>116</td><td>1</td></tr><tr><td>ABC0</td><td>05</td><td>2023</td><td>120</td><td>1</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "ABC2",
         "01",
         "2023",
         124,
         1
        ],
        [
         "ABC6",
         "02",
         "2023",
         89,
         1
        ],
        [
         "ABC32",
         "03",
         "2023",
         120,
         1
        ],
        [
         "ABC3",
         "04",
         "2023",
         116,
         1
        ],
        [
         "ABC0",
         "05",
         "2023",
         120,
         1
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "customer_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "month",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "year",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "customer_rating",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "rank_customer_rating",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df15.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca380bf3-411b-4c6b-9caf-31814677f5b0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save the DataFrame df_customer_spent_distance as a table named \"df_customer_spent_distance\"\n",
    "df_customer_spent_distance.write.saveAsTable(\"df_customer_spent_distance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Final_Reports",
   "notebookOrigID": 414574091445236,
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
